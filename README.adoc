= Kafka Demo on Kubernetes
:imagesdir: imgs
:toc:

== Pre-req

* Openshift 4.5 Cluster

== Demo

=== Kafka Operator

Our first step is to install the Kafka Operator. We will use the Strimzi Operator for this task.

==== Installing Kafka Operator (Strimzi)

* Access the Administrator console
* Click on Operators -> OperatorHub
* Search for Strimzi

image::2-10-2020-09-45-29-AM.png[] 

* Accept the Community warning

image::2-10-2020-09-46-43-AM.png[] 

* Click on `Install`

image::2-10-2020-09-47-09-AM.png[] 

* Select the `Stable` channel
* On `Installation Mode` choose `All namespaces on the cluster`
* Choose the approval strategy as `Automatic`
* Click on `Install`

image::2-10-2020-09-47-53-AM.png[] 

* Now wait for the operator status change to `Succeeded`

image::2-10-2020-09-48-39-AM.png[] 

=== Projects/Namespaces

* From the Administrator perspective, click on `Project` and then `Create Project` on the right corner

image::2-10-2020-09-53-57-AM.png[] 

* Fill out the form
  * Name: kafka-demo
  * Display Name: Kafka Demo
  * Description: Kafka Demo
* Click on `Create`

image::2-10-2020-09-54-47-AM.png[] 

* Then you should see the following screen

image::2-10-2020-09-55-16-AM.png[] 

=== Kafka Broker

==== Kafka Cluster

* Go to the Developer Perspective

image::4-10-2020-09-46-46-AM.png[] 

* Click on `Add` -> `Operator Backed`

image::4-10-2020-09-49-14-AM.png[] 

* Choose `Kafka`

image::4-10-2020-09-50-14-AM.png[] 

* And click on `Create` button

image::4-10-2020-09-51-08-AM.png[] 

* Switch to the `YAML view` and change the listeners according to the image below. Then click on `Create`

image::2-10-2020-10-00-35-AM.png[] 

* Here you have the full yaml. If you want, you can copy and paste

[source,yaml]
----
apiVersion: kafka.strimzi.io/v1beta1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    version: 2.5.0
    replicas: 3
    listeners:
      plain: {}
      tls: {}
    config:
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2
      log.message.format.version: "2.5"
    storage:
      type: ephemeral
  zookeeper:
    replicas: 3
    storage:
      type: ephemeral
  entityOperator:
    topicOperator: {}
    userOperator: {}
----

After you cluster is installed, you will see:

image::4-10-2020-17-00-35-PM.png[] 

You can also see the Kafka cluster using the kubectl command:

[source,bash]
----
kubectl get kafka -n kafka-demo

# Short name for kafka
kubectl get k -n kafka-demo
----

image::4-10-2020-17-01-50-PM.png[] 

=== Developer Console

==== Customizing the Dev Console

image::2-10-2020-10-02-47-AM.png[] 

* If you are in the Administration Perspective, switch to Developer Perspective
* Add Kafka, KafkaTopic to the Dev console
  * Click on `Search` and search for the Kafka and KafkaTopic CR
  * Click on `add to navigation`

image::2-10-2020-10-05-11-AM.png[] 

image::2-10-2020-10-06-21-AM.png[] 

image::2-10-2020-10-06-58-AM.png[] 

* Repeat the same process to the add the following resources to the side menu:
  ** `KafkaBridge`
  ** `KafkaConnect`
  ** `KafkaConnector`
  ** `KafkaMirrorMaker2`
  ** `KafkaRebalance`
  ** `Service`
  ** `Route`

* Your menu should look like that

image::4-10-2020-10-25-34-AM.png[] 

* You can remove any item on the menu by clicking on the `(-)` . It will appear when you hover the mouse over the item.

image::4-10-2020-10-21-31-AM.png[] 

* And then `Remove` from navigation

image::4-10-2020-10-22-17-AM.png[] 

==== Explore the Dev Console

* After Kafka cluster is fully installed, you can see the Details, Resources and Monitoring

image::2-10-2020-10-34-11-AM.png[] 

image::2-10-2020-10-32-36-AM.png[] 

image::2-10-2020-10-35-06-AM.png[] 

image::2-10-2020-10-36-20-AM.png[] 

==== Create Topics

===== Create Topic Using KafkaTopic

* Make sure you are in the right project and click on `Add` -> `Operator Backed`

image::4-10-2020-09-49-14-AM.png[] 

* Now choose `Kafka Topic` and then `Create`

image::4-10-2020-16-06-32-PM.png[] 

image::4-10-2020-16-06-58-PM.png[] 

* Fill out the forms using the values:
** Name: `first-topic`
** Partitions: `3`
** Replication Factor: 3
* And now click on `Create`

image::4-10-2020-16-45-55-PM.png[] 

* You can use the YAML editor as well:

image::2-10-2020-10-44-10-AM.png[]  

[source,yaml]
----
apiVersion: kafka.strimzi.io/v1beta1
kind: KafkaTopic
metadata:
  name: first-topic
  labels:
    strimzi.io/cluster: my-cluster
  namespace: strimzi-operator
spec:
  config:
    retention.ms: 604800000
    segment.bytes: 1073741824
  partitions: 3
  replicas: 3
  topicName: first-topic
----

Now let's set some vars

[variables]
[source,bash]
----
export KAFKA_NAMESPACE=kafka-demo
export ZOOKEEPER_HOST=localhost:2181
export BROKER_HOST=localhost:9092
export ZOOKEEPER_POD=$(kubectl -n $KAFKA_NAMESPACE get pods -l app.kubernetes.io/name=zookeeper -o=jsonpath='{.items[0].metadata.name}')
export KAFKA_BROKER_POD=$(kubectl -n $KAFKA_NAMESPACE get pods -l app.kubernetes.io/name=kafka -o=jsonpath='{.items[0].metadata.name}')
export SUBDOMAIN=$(kubectl get ingresses.config.openshift.io -o jsonpath='{.items[0].spec.domain}')
echo
echo $ZOOKEEPER_POD
echo $KAFKA_BROKER_POD
echo $SUBDOMAIN
----

[source,bash]
----
kubectl -n $KAFKA_NAMESPACE exec -it $KAFKA_BROKER_POD -c kafka -- bin/kafka-topics.sh \
    --list \
    --zookeeper $ZOOKEEPER_HOST
----

image::2-10-2020-11-35-33-AM.png[] 

[source,bash]
----
kubectl -n $KAFKA_NAMESPACE exec -it $KAFKA_BROKER_POD -c kafka -- bin/kafka-topics.sh \
    --zookeeper $ZOOKEEPER_HOST \
    --topic first-topic \
    --describe
----

image::2-10-2020-11-36-48-AM.png[] 

===== Create Topic Using Kafka CLI

Create topic using kafka-topics.sh

[source,bash]
----
kubectl -n $KAFKA_NAMESPACE exec -it $KAFKA_BROKER_POD -c kafka -- bin/kafka-topics.sh \
    --create \
    --zookeeper $ZOOKEEPER_HOST \
    --replication-factor 1 \
    --partitions 2 \
    --topic second-topic
----

List topics

[source,bash]
----
kubectl -n $KAFKA_NAMESPACE exec -it $KAFKA_BROKER_POD -c kafka -- bin/kafka-topics.sh \
    --list \
    --zookeeper $ZOOKEEPER_HOST
----

image::2-10-2020-17-30-37-PM.png[] 

We can see the Kafka Topic CR was created as well:

image::2-10-2020-17-32-30-PM.png[] 

We can also check that by running:

[source,bash]
----
kubectl get kafkatopic -n $KAFKA_NAMESPACE
----

image::4-10-2020-17-02-32-PM.png[] 

=== Producer and Consumer

Now let's producer some messages.

Open the command below in a terminal tab

.producer
[source,bash]
----
kubectl -n $KAFKA_NAMESPACE exec -it $KAFKA_BROKER_POD -c kafka -- bin/kafka-console-producer.sh \
    --broker-list $BROKER_HOST \
    --topic first-topic
----

Open the command below in another terminal tab:

.consumer
[source,bash]
----
kubectl -n $KAFKA_NAMESPACE exec -it $KAFKA_BROKER_POD -c kafka -- bin/kafka-console-consumer.sh \
    --bootstrap-server $BROKER_HOST \
    --topic first-topic
----

TIP: Do not forget to <<variables,set the requirement variables>>

Anything you write in the producer tab, will be shown in the consumer tab.

image::2-10-2020-17-58-00-PM.png[] 

=== VR Application

Take note of the bootstrap service from your kafka cluster. We will need it in the next labs.

image::2-10-2020-18-21-57-PM.png[] 

And use it in the `KAFKA_BROKER` variable:

[source,bash]
----
oc process -f vr-template.yml \
  -p NAMESPACE=$KAFKA_NAMESPACE \
  -p KAFKA_BROKER=my-cluster-kafka-bootstrap:9092 \
  -p KAFKA_TOPIC=third-topic \
  -p SUBDOMAIN=$SUBDOMAIN \
  | kubectl apply -f -
----

After running this, we will see a new application in the developer console:

image::3-10-2020-10-38-26-AM.png[] 

Now, Open the Camel VR Route

image::3-10-2020-10-40-09-AM.png[] 

We will see the VR Application:

image::3-10-2020-10-45-08-AM.png[] 

Now click many times on the `Send Event` to send message to the `third-topic`:

image::3-10-2020-10-45-53-AM.png[] 

We will see the message flowing throught the kafka Consumer and the offset 0 will be created.

image::3-10-2020-10-47-19-AM.png[] 

Now open the swagger url:

image::3-10-2020-10-48-41-AM.png[] 

Add the following by the end of the url: `/webjars/swagger-ui/2.1.0/index.html?url=/camel/api-docs`

image::3-10-2020-10-50-02-AM.png[] 

=== Consumer and Producer Application

Now let's create another topic: `forth-topic`

For that, let's use the import yaml editor.

image::4-10-2020-17-28-42-PM.png[] 

And paste the following yaml:

[source,yaml]
----
apiVersion: kafka.strimzi.io/v1beta1
kind: KafkaTopic
metadata:
  name: forth-topic
  labels:
    strimzi.io/cluster: my-cluster
  namespace: kafka-demo
spec:
  config:
    retention.ms: 604800000
    segment.bytes: 1073741824
  partitions: 3
  replicas: 3
  topicName: forth-topic
----

Let's see if it was created corretly:

[source,bash]
----
kubectl -n $KAFKA_NAMESPACE exec -it $KAFKA_BROKER_POD -c kafka -- bin/kafka-topics.sh \
    --zookeeper $ZOOKEEPER_HOST \
    --topic forth-topic \
    --describe
----

Now let's deploy the consumer and producer.

[source,bash]
----
oc process -f consumer-producer-template.yml \
  -p NAMESPACE=$KAFKA_NAMESPACE \
  -p TOPIC=forth-topic \
  -p KAFKA_BROKER=my-cluster-kafka-bootstrap:9092 \
  | kubectl apply -f -
----

Wait for both pods become ready and run:

[source,bash]
----
kubectl logs --tail 100 -f $(kubectl get pods -l app=hello-world-producer -o jsonpath='{.items[0].metadata.name}')
----

[source,bash]
----
kubectl logs --tail 100 -f $(kubectl get pods -l app=hello-world-consumer -o jsonpath='{.items[0].metadata.name}')
----

Your terminal should be like this:

image::4-10-2020-19-00-43-PM.png[] 

==== Change the cluster config

[update-cluster]
Now let's change the Kafka configuration.

Click on `Kafkas` on the left menu and then edit our cluster CR:

image::4-10-2020-19-04-45-PM.png[] 

In the config section, add `log.retention.hours: 200` as shown below:

image::4-10-2020-19-09-24-PM.png[] 

[source,yaml]
----
apiVersion: kafka.strimzi.io/v1beta1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    version: 2.5.0
    replicas: 3
    listeners:
      plain: {}
      tls: {}
    config:
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2
      log.message.format.version: "2.5"
      log.retention.hours: 200 <1>
    storage:
      type: ephemeral
  zookeeper:
    replicas: 3
    storage:
      type: ephemeral
  entityOperator:
    topicOperator: {}
    userOperator: {}
----
<1> Added

And then click on `Save` button.

=== Topic View Application

Now let's deploy a Topic View app. Run in your terminal:

[source,bash]
----
oc process -f topic-view-template.yml \
  -p NAMESPACE=$KAFKA_NAMESPACE \
  -p KAFKA_BROKER=my-cluster-kafka-bootstrap:9092 \
  -p SUBDOMAIN=$SUBDOMAIN \
  | kubectl apply -f -
----

Now open it by clicking on the arrow icon:

image::5-10-2020-09-11-48-AM.png[] 

You will see this:

image::5-10-2020-09-12-24-AM.png[] 

==== Scale Kafka Cluster

Before we scale our cluster, let's create two more topics.

* Make sure you are in the right project and click on `Add` -> `Operator Backed`

image::4-10-2020-09-49-14-AM.png[] 

* Now choose `Kafka Topic` and then `Create`

image::4-10-2020-16-06-32-PM.png[] 

image::4-10-2020-16-06-58-PM.png[] 

* Fill out the form using the values:
** Name: `topic-hundred-partitions`
** Partitions: `100`
** Replication Factor: `3`
* And now click on `Create`

image::4-10-2020-16-45-55-PM.png[] 

* You can use the YAML editor as well:

image::2-10-2020-10-44-10-AM.png[] 

.hundred-topic
[source,yaml]
----
apiVersion: kafka.strimzi.io/v1beta1
kind: KafkaTopic
metadata:
  name: topic-hundred-partitions
  labels:
    strimzi.io/cluster: my-cluster
  namespace: kafka-demo
spec:
  config:
    retention.ms: 604800000
    segment.bytes: 1073741824
  partitions: 100
  replicas: 3
----

Repeat the same step above and create another topic with the following config:

* Name: `topic-two-hundred-partitions`
* Partitions: `200`
* Replication Factor: `3`

.two-hundred-topic
[source,yaml]
----
apiVersion: kafka.strimzi.io/v1beta1
kind: KafkaTopic
metadata:
  name: topic-two-hundred-partitions
  labels:
    strimzi.io/cluster: my-cluster
  namespace: kafka-demo
spec:
  config:
    retention.ms: 604800000
    segment.bytes: 1073741824
  partitions: 200
  replicas: 3
----

Let's make sure the topic were created:

[source,bash]
----
kubectl -n $KAFKA_NAMESPACE exec -it $KAFKA_BROKER_POD -c kafka -- bin/kafka-topics.sh \
    --list \
    --zookeeper $ZOOKEEPER_HOST
----

image::5-10-2020-09-39-36-AM.png[] 

Now we can scale up our cluster. For that, change the kafka replica to `5`. For that follow <<update-cluster,the steps of changing the cluster>>.

[source,yaml]
----
apiVersion: kafka.strimzi.io/v1beta1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    version: 2.5.0
    replicas: 5 <1>
    listeners:
      plain: {}
      tls: {}
    config:
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2
      log.message.format.version: "2.5"
    storage:
      type: ephemeral
  zookeeper:
    replicas: 3
    storage:
      type: ephemeral
  entityOperator:
    topicOperator: {}
    userOperator: {}
----
<1> Increased

We can check the number os broker by looking at the pods count.

image::5-10-2020-10-26-18-AM.png[] 

Now go back to the Topic View App

image::5-10-2020-10-27-03-AM.png[] 

As you can see, our cluster is not balanced. To fix that, we'll use the Cruise Control.

=== Cruise Control

==== Deploy Cruise Control

Our first step is to install Cruise Control. For that change you Kafka Cluster adding `cruiseControl: {}` by the end of the file.

[source,yaml]
----
apiVersion: kafka.strimzi.io/v1beta1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    version: 2.5.0
    replicas: 5
    listeners:
      plain: {}
      tls: {}
    config:
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2
      log.message.format.version: "2.5"
    storage:
      type: ephemeral
  zookeeper:
    replicas: 3
    storage:
      type: ephemeral
  entityOperator:
    topicOperator: {}
    userOperator: {}
  cruiseControl: {} <1>
----
<1> Added

All kafka instances will reboot and a Cruise Control pod will come up.

image::5-10-2020-10-33-06-AM.png[] 

==== Deploy Rebalance

Now let's apply the rebalance policy.

* Make sure you are in the right project and click on `Add` -> `Operator Backed`

image::4-10-2020-09-49-14-AM.png[] 

* Now click on `Kafka Rebalance`

image::5-10-2020-10-36-37-AM.png[] 

* Click on `Create`

image::5-10-2020-10-37-17-AM.png[] 

* Switch to YAML View and use the content below:

[source,yaml]
----
apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaRebalance
metadata:
  name: my-rebalance
  labels:
    strimzi.io/cluster: my-cluster
  namespace: kafka-demo
spec:
  goals:
    - NetworkInboundCapacityGoal
    - DiskCapacityGoal
    - RackAwareGoal
    - NetworkOutboundCapacityGoal
    - ReplicaCapacityGoal
    - TopicReplicaDistributionGoal
    - LeaderReplicaDistributionGoal
    - LeaderBytesInDistributionGoal
----

image::5-10-2020-10-38-53-AM.png[] 

* Click on `Create`

You can also see the KafkaRebalance CR using the kubectl command:

[source,bash]
----
kubectl get kafkarebalance -n $KAFKA_NAMESPACE

# Short name for kafka rebalance
kubectl get kr -n $KAFKA_NAMESPACE
----

* Now let's see the proposal plan generate from Cruise Control. Open the KafkaRebalance CR.

image::5-10-2020-10-40-47-AM.png[] 

* Go to the bottom of the yaml and you will see the proposal:

image::5-10-2020-10-41-56-AM.png[] 

* Now let's approve our rebalance plan.

image::5-10-2020-10-45-34-AM.png[] 

* Key: `strimzi.io/rebalance`
* Value: `approve`

image::5-10-2020-10-52-47-AM.png[] 

* We can see the progress of our plan by reloading the yaml:

image::5-10-2020-10-47-04-AM.png[] 

image::5-10-2020-10-47-30-AM.png[] 

* Now if we switch back to the Topic View App, we can see that broker 4 and 5 has more partition, data and leader.

image::5-10-2020-10-50-41-AM.png[] 

We can improve it by increasing the rebalance goals.

=== Monitoring

[source,yaml]
----
apiVersion: kafka.strimzi.io/v1beta1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    version: 2.5.0
    replicas: 5
    listeners:
      plain: {}
      tls: {}
    config:
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2
      log.message.format.version: "2.5"
    storage:
      type: ephemeral
    metrics: {}
  zookeeper:
    replicas: 3
    storage:
      type: ephemeral
  entityOperator:
    topicOperator: {}
    userOperator: {}
  kafkaExporter: {}
----

=== Kafka Connect

==== Create Kafka Connect Cluster

To create a Kafka Connect cluster:

Make sure you are in the right project and click on `Add` -> `Operator Backed`

image::4-10-2020-09-49-14-AM.png[] 

Now select `Kafka Connect`

image::5-10-2020-11-09-48-AM.png[] 

And click on `Create`

image::5-10-2020-11-10-26-AM.png[] 

Switch to the YAML View and paste the content below:

[source,yaml]
----
apiVersion: kafka.strimzi.io/v1beta1
kind: KafkaConnect
metadata:
  name: my-connect-cluster
  annotations:
    strimzi.io/use-connector-resources: "true"
spec:
  version: 2.5.0
  replicas: 1
  bootstrapServers: my-cluster-kafka-bootstrap:9092
  config:
    group.id: connect-cluster
    offset.storage.topic: connect-cluster-offsets
    config.storage.topic: connect-cluster-configs
    status.storage.topic: connect-cluster-status
----

Now click on `Create`

You can also see the KafkaConnect CR using the kubectl command:

[source,bash]
----
kubectl get kafkaconnect -n $KAFKA_NAMESPACE

# Short name for kafka connect
kubectl get kc -n $KAFKA_NAMESPACE
----

Go back to the Topology View and select the Application `strimzi-my-connect-cluster`

image::3-10-2020-14-52-18-PM.png[] 

Wait for the pod to be ready.

==== Create Kafka Connector

Make sure you are in the right project and click on `Add` -> `Operator Backed`

image::4-10-2020-09-49-14-AM.png[] 

Now select `Kafka Connector`

image::5-10-2020-11-18-57-AM.png[] 

And click on `Create`

image::5-10-2020-11-19-54-AM.png[] 

Switch to the YAML View and paste the content below

[source,yaml]
----
apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnector
metadata:
  name: my-source-connector
  labels:
    strimzi.io/cluster: my-connect-cluster
spec:
  class: org.apache.kafka.connect.file.FileStreamSourceConnector
  tasksMax: 1
  config:
    file: "/tmp/my-special-file"
    topic: my-topic-connect
----

image::5-10-2020-11-23-24-AM.png[] 

Click on `Create`

You can also see the KafkaConnector CR using the kubectl command:

[source,bash]
----
kubectl get kafkaconnector -n $KAFKA_NAMESPACE

# Short name for kafka connector
kubectl get kctr -n $KAFKA_NAMESPACE
----

Now on the terminal, run:

[source,bash]
----
kubectl -n $KAFKA_NAMESPACE exec -it $KAFKA_BROKER_POD -c kafka -- bin/kafka-console-consumer.sh \
    --bootstrap-server $BROKER_HOST \
    --topic my-topic-connect \
    --from-beginning
----

In other terminal tab, run:

[source,bash]
----
KAFKA_CONNECT_POD=$(kubectl -n $KAFKA_NAMESPACE get pods -l app.kubernetes.io/name=kafka-connect -o=jsonpath='{.items[0].metadata.name}')

kubectl -n $KAFKA_NAMESPACE exec -it $KAFKA_CONNECT_POD -- /bin/bash -c "echo 'hello' >> /tmp/my-special-file"

kubectl -n $KAFKA_NAMESPACE exec -it $KAFKA_CONNECT_POD -- /bin/bash -c "echo 'hello again' >> /tmp/my-special-file"
----

=== Kafka Bridge

==== Install Bridge

Make sure you are in the right project and click on `Add` -> `Operator Backed`

image::4-10-2020-09-49-14-AM.png[] 

Now select `Kafka Bridge`

image::5-10-2020-11-42-33-AM.png[] 

And click on `Create`

Switch to the YAML View and paste the content below:

[source,yaml]
----
apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaBridge
metadata:
  name: my-bridge
spec:
  replicas: 1
  bootstrapServers: my-cluster-kafka-bootstrap:9092
  http:
    port: 8080
----

And click on `Create`

image::5-10-2020-11-46-11-AM.png[] 

You can also see the KafkaBridge CR using the kubectl command:

[source,bash]
----
kubectl get kafkabridge -n $KAFKA_NAMESPACE

# Short name for kafka bridge
kubectl get kb -n $KAFKA_NAMESPACE
----

In the Topology View, change application to `strimzi-my-bridge`

image::5-10-2020-11-47-51-AM.png[] 

Wait for the pod to be ready before moving on.

==== Create Route for Kafka Bridge

Go to the `Routes` on the left menu and click on `Create Route`

image::5-10-2020-11-59-06-AM.png[] 

Now fill out the form as below:

* Name: `kafka-bridge`
* Service: my-bridge-bridge-service
* Target Port: 8080 -> 8080 (TCP)

image::5-10-2020-12-07-01-PM.png[]

And click on `Create`

Now copy the Kafka Bridge URL and use it in the var below:

image::5-10-2020-12-08-53-PM.png[] 

[source,bash]
----
export KAFKA_BRIDGE_ROUTE="http://kafka-bridge-kafka-demo.apps.cluster-brasilia-9b97.brasilia-9b97.sandbox1457.opentlc.com/"
----

==== Produce Message

[source,bash]
----
curl -s -X POST \
  $KAFKA_BRIDGE_ROUTE/topics/topic-bridge \
  -H 'content-type: application/vnd.kafka.json.v2+json' \
  -d '{
    "records": [
        {
            "key": "my-key",
            "value": "100"
        },
        {
            "key": "my-key",
            "value": "200"
        }
    ]
}' | jq
----

image::5-10-2020-12-10-51-PM.png[] 

==== Consume message

===== Create consumer

Create consumer group `my-group` and consumer `my-consumer`

[source,bash]
----
curl -s -X POST $KAFKA_BRIDGE_ROUTE/consumers/my-group \
  -H 'content-type: application/vnd.kafka.v2+json' \
  -d '{
    "name": "my-consumer",
    "format": "json",
    "auto.offset.reset": "earliest",
    "enable.auto.commit": false
  }' | jq
----

image::5-10-2020-12-12-03-PM.png[] 

===== Subscribe to Topic

Subscribe to the topic `topic-bridge`

[source,bash]
----
curl -v -X POST $KAFKA_BRIDGE_ROUTE/consumers/my-group/instances/my-consumer/subscription \
  -H 'content-type: application/vnd.kafka.v2+json' \
  -d '{
    "topics": [
        "topic-bridge",
        "my-topic-connect"
    ]
}'
----

image::5-10-2020-12-12-37-PM.png[] 

===== Consume message

[source,bash]
----
curl -X GET $KAFKA_BRIDGE_ROUTE/consumers/my-group/instances/my-consumer/records \
  -H 'accept: application/vnd.kafka.json.v2+json' | jq
----

image::5-10-2020-12-13-29-PM.png[] 

=== Mirror Maker 2

==== Create additional Kafka Cluster

* Click on `Add` -> `Operator Backed`

image::4-10-2020-09-49-14-AM.png[] 

* Choose `Kafka`

image::4-10-2020-09-50-14-AM.png[] 

* And click on `Create` button

image::4-10-2020-09-51-08-AM.png[] 

* Switch to the `YAML view` paste the content below:

[source,yaml]
----
apiVersion: kafka.strimzi.io/v1beta1
kind: Kafka
metadata:
  name: my-cluster2
spec:
  kafka:
    version: 2.5.0
    replicas: 3
    listeners:
      plain: {}
      tls: {}
    config:
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2
      log.message.format.version: "2.5"
    storage:
      type: ephemeral
  zookeeper:
    replicas: 3
    storage:
      type: ephemeral
  entityOperator:
    topicOperator: {}
    userOperator: {}
----

* Click on `Create`

image::5-10-2020-12-44-14-PM.png[] 

* Now go to the topology view and choose the Application 

image::5-10-2020-12-46-22-PM.png[] 

==== Listing topic in Kafka cluster 2

Now let's see which topic we have in our Kafka cluster 2

[source,bash]
----
kubectl -n $KAFKA_NAMESPACE exec -it my-cluster2-kafka-0 -c kafka -- bin/kafka-topics.sh \
    --list \
    --zookeeper $ZOOKEEPER_HOST
----

image::5-10-2020-12-48-50-PM.png[] 

As you can see, cluster is empty.

==== Install Mirror Maker 2

* Click on `Add` -> `Operator Backed`

image::4-10-2020-09-49-14-AM.png[] 

* Choose `Kafka MirrorMaker2`

image::5-10-2020-12-52-57-PM.png[] 

* Click on `Create`

image::5-10-2020-12-53-33-PM.png[] 

* Switch to the `YAML View` and paste the following content:

[source,yaml]
----
apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaMirrorMaker2
metadata:
  name: my-mirror-maker
spec:
  version: 2.5.0
  replicas: 1
  connectCluster: "my-cluster2"
  clusters:
  - alias: "my-cluster"
    bootstrapServers: my-cluster-kafka-bootstrap:9092
  - alias: "my-cluster2"
    bootstrapServers: my-cluster2-kafka-bootstrap:9092
  mirrors:
  - sourceCluster: "my-cluster"
    targetCluster: "my-cluster2"
    sourceConnector:
      config:
        replication.factor: 1
        offset-syncs.topic.replication.factor: 1
        sync.topic.acls.enabled: "false"
    heartbeatConnector:
      config:
        heartbeats.topic.replication.factor: 1
    checkpointConnector:
      config:
        checkpoints.topic.replication.factor: 1
    topicsPattern: "^forth.*"
----

You can also see the KafkaMirrorMaker2 CR using the kubectl command:

[source,bash]
----
kubectl get kafkamirrormaker2 -n $KAFKA_NAMESPACE

# Short name for kafka mirror maker 2
kubectl get kmm2 -n $KAFKA_NAMESPACE
----

Go to the topology view and choose the application `strimzi-my-mirror-maker`

image::5-10-2020-13-02-08-PM.png[] 

Wait for the pod to be ready.

Now list again the topic of the kafka cluster 2.

[source,bash]
----
kubectl -n $KAFKA_NAMESPACE exec -it my-cluster2-kafka-0 -c kafka -- bin/kafka-topics.sh \
    --list \
    --zookeeper $ZOOKEEPER_HOST
----

You should see now a new topic with name `my-cluster.forth-topic`

Let's see if the message are been replicated to this new topic:

[source,bash]
----
kubectl -n $KAFKA_NAMESPACE exec -it my-cluster2-kafka-0 -c kafka -- bin/kafka-console-consumer.sh \
    --bootstrap-server $BROKER_HOST \
    --topic my-cluster.forth-topic
----

image::5-10-2020-13-04-31-PM.png[] 

[source,bash]
----
kubectl -n $KAFKA_NAMESPACE exec -it my-cluster2-kafka-0 -c kafka -- bin/kafka-topics.sh \
    --zookeeper $ZOOKEEPER_HOST \
    --topic my-cluster.forth-topic \
    --describe
----